{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## The different categories in which pre trained model was trained..\n",
    "cat = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car','cat', 'chair', 'cow',\n",
    "       'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "def detect_obj_and_draw_boxes(net, image): ## params: a neural net and an image on which we wanna run the detection\n",
    "    h, w = image.shape[:2]\n",
    "    resized = cv2.resize(image, (300,300)) ## because our caffe model was trained on 300,300 images.\n",
    "    blob = cv2.dnn.blobFromImage(resized, 0.007843, (300,300), 127.5) ## just a Preprocessing step.\n",
    "    \n",
    "    # feed the blob as input to our deep learning model.\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()[0][0]\n",
    "    \n",
    "    ## Loop over the detections\n",
    "    for i in range(len(detections)):\n",
    "        ## format of Each detection- [0, predicted category, confidence_value, x1, y1, x2, y2]\n",
    "        confidence = round(detections[i][2]*100, 2)\n",
    "        cat_idx = int(detections[i][1])\n",
    "        \n",
    "        # Confidence threshold:\n",
    "        if confidence > 60:\n",
    "            # scale up the box coordinates.\n",
    "            box = detections[i][3:]*np.array([w, h, w, h]) \n",
    "            \n",
    "            #covert them to int \n",
    "            (x1, y1, x2, y2) = box.astype('int')\n",
    "            obj_name = cat[cat_idx]\n",
    "            display = obj_name + ':' + str(confidence) + '%'\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0,0,255), 4)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(image, display, (x1, y1), font, 1, (0,255,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = '''The file can be image or a video. TO read video from webcam pass filename as 0'''\n",
    "\n",
    "data_file = '/home/aakash/opencv-4/video2.mp4'\n",
    "file_type = None\n",
    "\n",
    "if data_file.split('.')[1] in ['png', 'jpg', 'jpeg']:\n",
    "    file_type = 'image'\n",
    "    \n",
    "if data_file.split('.')[1] in ['mp4', 'avi', 'mov']:\n",
    "    file_type = 'video'\n",
    "    \n",
    "# Load the caffe model\n",
    "model_name = '/home/aakash/opencv-4/object-detection-deep-learning/MobileNetSSD_deploy.caffemodel'\n",
    "model_proto = '/home/aakash/opencv-4/object-detection-deep-learning/MobileNetSSD_deploy.prototxt.txt'\n",
    "net = cv2.dnn.readNetFromCaffe(model_proto, model_name)\n",
    "\n",
    "if file_type == 'image':\n",
    "    test_image = cv2.imread(data_file)\n",
    "    detect_obj_and_draw_boxes(net, test_image)\n",
    "    cv2.imshow('image', test_image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "if file_type == 'video':\n",
    "    cap = cv2.VideoCapture(data_file)\n",
    "    while True:\n",
    "        ret, frame = cap.read() # ret = return value is a boolean variable\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        detect_obj_and_draw_boxes(net, frame)    \n",
    "        cv2.imshow('Demo', frame) # every video can be broken down into a series of images.\n",
    "\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == ord('q'):\n",
    "            cap.release()\n",
    "            break  \n",
    "cv2.destroyAllWindows()          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
