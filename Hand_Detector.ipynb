{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build an app to identify the presence of human hand!!\n",
    "# Outline its coordinates and locate the fingertips as well.\n",
    "## Building an hand writing app!\n",
    "## First we will segment the hand out fram input video..\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "def capture_histogram(source):\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # frame = cv2.resize(frame, (1000, 600))\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame, 'place region of hand inside the box and press a', (5, 50), font, 0.7,  (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(frame, (500,100), (580, 180), (105,105,105), 2)\n",
    "        box = frame[105:175, 505:575]\n",
    "        \n",
    "        cv2.imshow('capture histogram', frame)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            break\n",
    "            \n",
    "        if k == ord('a'):\n",
    "            object_color = box\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            break\n",
    "    ## Because it is easier to calculate histogram of HSV.\n",
    "    obj_color_hsv = cv2.cvtColor(object_color, cv2.COLOR_BGR2HSV)\n",
    "    obj_hist = cv2.calcHist([obj_color_hsv], [0, 1], None, [12, 15], [0, 180, 0, 256])\n",
    "        # [0, 1] means we are computing histogram for 2 channels 0th and 1st..\n",
    "        ## None because we are not using a mask..\n",
    "        # [12, 15] denotes the no. of bins in the corresponding channel..\n",
    "        # [0, 180, 0, 256] denote the range of each channel..\n",
    "    cv2.normalize(obj_hist,obj_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "    return obj_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing backproj. on input video feed..\n",
    "def locate_object(frame, obj_hist):\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) ## Image in which we want to compute the backprojection.\n",
    "    ## Apply back_projection using obj_hist as model histogram.\n",
    "    obj_seg = cv2.calcBackProject([hsv_frame], [0,1], obj_hist, [0, 180, 0, 255], 1)\n",
    "    ## 1 is just a scaling factor.\n",
    "    _, seg_thresh = cv2.threshold(obj_seg, 70, 255, cv2.THRESH_BINARY) #This is unenhanced version of the original image. \n",
    "    \n",
    "    ## applying some image operations to enhance the image..\n",
    "    kernel = None\n",
    "    disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15)) ## To get a circular filter..\n",
    "    filtered = cv2.filter2D(seg_thresh, -1, disc) ## Applying that disc kernel over the segmented image.\n",
    "    # So when we apply such a filter it tends to smoothen out the image and makes the image easier to visualise..\n",
    "    eroded = cv2.erode(filtered, kernel, iterations = 2)\n",
    "    dilated = cv2.dilate(filtered, kernel, iterations = 2)\n",
    "    closing = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel) ## Closing is dilation followed by erosion.\n",
    "    ## And this is a black and white enhanced image of our object..\n",
    "    \n",
    "    ## Masking \n",
    "    masked = cv2.bitwise_and(frame, frame, mask = closing)\n",
    "    return closing, masked, seg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hand(frame, hist):\n",
    "    return_val = {}\n",
    "    detected_hand, masked, raw = locate_object(frame, hist)\n",
    "    return_val['binary'] = detected_hand\n",
    "    return_val['masked'] = masked\n",
    "    return_val['raw'] = raw\n",
    "    \n",
    "    ## Now we will also find the boundaries of the image.\n",
    "    image, cont, _ = cv2.findContours(detected_hand, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # The last two params are commonly used to find the boundaries or contours.\n",
    "    \n",
    "    palm_area = 0\n",
    "    flag_area = None\n",
    "    cnt = None\n",
    "    \n",
    "    for (i,c) in enumerate(cont):\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > palm_area:\n",
    "            palm_area = area\n",
    "            flag = i\n",
    "    ## This was just to find the biggest contour.        \n",
    "    if flag is not None and palm_area > 10000: # if flag is not none means we have found some boundary.\n",
    "        cnt = cont[flag]\n",
    "        return_val['contour'] = cnt\n",
    "        cpy = frame.copy()\n",
    "        cv2.drawContours(cpy, [cnt], 0, (0, 255, 0), 2) ## third arg. is the contour index..\n",
    "        return_val['boundaries'] = cpy\n",
    "        return True, return_val\n",
    "    else:\n",
    "        return False, return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    return math.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points(points, filter_val):\n",
    "    for i in range(len(points)):\n",
    "        for j in range(i+1, len(points)):\n",
    "            if points[i] and points[j] and dist(points[i], points[j]) < filter_val:\n",
    "                points[j] = None\n",
    "    filtered = []            \n",
    "    for point in points:\n",
    "        if point is not None:\n",
    "            filtered.append(point)\n",
    "    return filtered        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fingertips(hand):\n",
    "    cnt = hand['contour']\n",
    "    pts = []\n",
    "    hull = cv2.convexHull(cnt, returnPoints = False) #False because we want to compute the indices of defects of HULL\n",
    "    defects = cv2.convexityDefects(cnt, hull)\n",
    "    \n",
    "    ## Getting all the end points using defects and contours.\n",
    "    for i in range(defects.shape[0]): ## Iterating over the rows.\n",
    "        s,e,f,d = defects[i,0] # start pt, end pt, far pt, distance to farthest point..\n",
    "        end = tuple(cnt[e][0])\n",
    "        pts.append(end)\n",
    "        \n",
    "    ## Filter out the points which are too close to each other.\n",
    "    filtered = filter_points(pts, 50) ## 50 is the minimum distance between two points..\n",
    "    \n",
    "    ## sort the fingertips in order of increasing y-coordinate..\n",
    "    filtered.sort(key = lambda y: y[1])\n",
    "    \n",
    "    return [pt for idx, pt in zip(range(5), filtered)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame, points):\n",
    "    radius = 5\n",
    "    color = (0,0,255)\n",
    "    thickness = -1\n",
    "    for point in points:\n",
    "        cv2.circle(frame, point, radius, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the model histogram for further use.\n",
    "hist = capture_histogram(0)\n",
    "np.save('hist.npy', hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now puttig it all together.\n",
    "# Testing it for a test image,\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## Initializing a black canvas. on the top of which we will draw something..\n",
    "screen = np.zeros((600, 1000))\n",
    "\n",
    "hist = np.load('hist.npy')\n",
    "\n",
    "curr = None\n",
    "prev = None ## These two variables will keep track of our fingertips\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (1000, 600))\n",
    "\n",
    "    bool_hand, hand = detect_hand(frame, hist) # bool_hand i.e whether we got desired contour/boundary.   \n",
    "    if bool_hand:\n",
    "        hand_image = hand['boundaries']\n",
    "        #cv2.imshow('Hand_detector', hand['boundaries'])\n",
    "        fingertips = extract_fingertips(hand)\n",
    "        plot(hand_image, fingertips)\n",
    "        #cv2.imshow('enhanced binary', hand['binary'])\n",
    "        #cv2.imshow('masked', hand['masked'])\n",
    "        #cv2.imshow('raw', hand['raw'])\n",
    "        prev = curr\n",
    "        curr = fingertips[0]\n",
    "        \n",
    "        if prev and curr:\n",
    "            cv2.line(screen, prev, curr, (255,0,0), 5)\n",
    "        cv2.imshow('hand_detected', hand_image)\n",
    "        cv2.imshow('draw', screen)    \n",
    "        \n",
    "    else:\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):\n",
    "        cap.release()\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
